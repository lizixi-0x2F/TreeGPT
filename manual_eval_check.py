#!/usr/bin/env python3
"""
æ‰‹åŠ¨è¯„ä¼°æ£€æŸ¥ - åŠ è½½æœ€ä½³æ£€æŸ¥ç‚¹å¹¶åœ¨evalé›†åˆä¸­æŠ½å‡ é“é¢˜æµ‹è¯•
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import json
import numpy as np
from pathlib import Path
import logging
from torch.utils.data import DataLoader

# Import our modules
from src.TreeGPT import *
from src.arc_treegpt import *

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_best_model():
    """åŠ è½½æœ€ä½³æ£€æŸ¥ç‚¹"""
    device = 'cpu'  # ä½¿ç”¨CPUé¿å…MPSå†…å­˜é—®é¢˜
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load('best_treeffn_seq2seq.pth', map_location=device)
    config = checkpoint['config']
    
    logger.info(f"ğŸ“Š Loaded checkpoint from step {checkpoint['step']} (epoch {checkpoint['epoch']})")
    logger.info(f"  Train loss: {checkpoint['train_loss']:.4f}")
    logger.info(f"  Token acc: {checkpoint['token_acc']:.4f}")
    logger.info(f"  Full acc: {checkpoint['full_acc']:.4f}")
    logger.info(f"  Val token acc: {checkpoint['val_token_acc']:.4f}")
    logger.info(f"  Val full acc: {checkpoint['val_full_acc']:.4f}")
    
    # åˆ›å»ºæ¨¡å‹
    from train_no_attention import TreeFFNSeq2SeqARC
    model = TreeFFNSeq2SeqARC(**config).to(device)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    logger.info(f"ğŸš€ Model loaded on {device}")
    logger.info(f"  Config: {config}")
    
    return model, device, checkpoint

def manual_evaluation(model, device, num_samples=5):
    """æ‰‹å·¥è¯„ä¼°å‡ ä¸ªæ ·æœ¬"""
    logger.info(f"ğŸ” Manual evaluation on {num_samples} samples")
    
    # åŠ è½½evalæ•°æ®
    eval_dataset = ARCDataset('arc-prize-2025/arc-agi_evaluation_challenges.json', max_length=8192)
    tokenizer = ARCGridTokenizer()
    
    model.eval()
    
    # éšæœºé€‰æ‹©å‡ ä¸ªæ ·æœ¬
    indices = torch.randperm(len(eval_dataset))[:num_samples].tolist()
    
    with torch.no_grad():
        for i, idx in enumerate(indices):
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ§ª Sample {i+1}/{num_samples} (Index: {idx})")
            
            # è·å–æ ·æœ¬
            sample = eval_dataset[idx]
            sample_id = sample['sample_id']
            input_ids = sample['input_ids'].unsqueeze(0).to(device)
            
            logger.info(f"  Sample ID: {sample_id}")
            logger.info(f"  Input length: {sample['input_length']}")
            logger.info(f"  Sequence length: {sample['seq_length']}")
            
            # åˆ›å»ºè¾“å…¥è¾“å‡º
            targets = input_ids[:, 1:].contiguous()
            inputs = input_ids[:, :-1].contiguous()
            
            # å‰å‘ä¼ æ’­
            logits = model(inputs)
            
            # é¢„æµ‹
            predictions = torch.argmax(logits, dim=-1)
            
            # è®¡ç®—å‡†ç¡®ç‡
            mask = (targets != 16)  # épadding token
            correct = (predictions == targets) & mask
            token_acc = (correct.sum().float() / mask.sum().float()).item() if mask.sum() > 0 else 0.0
            
            # æ£€æŸ¥å®Œæ•´åºåˆ—å‡†ç¡®ç‡
            batch_correct = True
            if mask.sum() > 0:
                sample_predictions = predictions[0][mask[0]]
                sample_targets = targets[0][mask[0]]
                batch_correct = torch.all(sample_predictions == sample_targets).item()
            full_acc = 1.0 if batch_correct else 0.0
            
            logger.info(f"  Token accuracy: {token_acc:.4f}")
            logger.info(f"  Full accuracy: {full_acc:.4f}")
            
            # æ˜¾ç¤ºä¸€äº›å…·ä½“çš„é¢„æµ‹vsç›®æ ‡å¯¹æ¯”
            if mask.sum() > 10:  # åªæœ‰è¶³å¤Ÿé•¿çš„åºåˆ—æ‰æ˜¾ç¤º
                valid_preds = predictions[0][mask[0]][:20]  # æ˜¾ç¤ºå‰20ä¸ªæœ‰æ•ˆtoken
                valid_targets = targets[0][mask[0]][:20]
                
                logger.info(f"  Predictions (first 20): {valid_preds.cpu().tolist()}")
                logger.info(f"  Targets    (first 20): {valid_targets.cpu().tolist()}")
                
                # æ‰¾å‡ºä¸åŒ¹é…çš„ä½ç½®
                mismatches = []
                for j, (pred, target) in enumerate(zip(valid_preds, valid_targets)):
                    if pred != target:
                        mismatches.append(f"pos_{j}: pred={pred.item()}, target={target.item()}")
                
                if mismatches:
                    logger.info(f"  Mismatches: {', '.join(mismatches)}")
                else:
                    logger.info(f"  âœ… Perfect match in first 20 tokens!")
            
            # å°è¯•è§£ç è¾“å‡ºç½‘æ ¼ï¼ˆå¦‚æœè¿™æ˜¯å®Œæ•´çš„ARCä»»åŠ¡ï¼‰
            try:
                # è·å–åŸå§‹æ•°æ®ä»¥äº†è§£ä»»åŠ¡ç»“æ„
                with open('arc-prize-2025/arc-agi_evaluation_challenges.json', 'r') as f:
                    original_data = json.load(f)
                
                if sample_id in original_data:
                    task_data = original_data[sample_id]
                    logger.info(f"  Task has {len(task_data['train'])} training examples")
                    
                    # æ˜¾ç¤ºè¾“å…¥ç½‘æ ¼å¤§å°
                    test_input = task_data['test'][0]['input']
                    logger.info(f"  Test input grid size: {len(test_input)}x{len(test_input[0])}")
                    
                    # å¦‚æœæœ‰ground truthè¾“å‡ºï¼Œæ˜¾ç¤ºæœŸæœ›çš„è¾“å‡ºç½‘æ ¼å¤§å°
                    if 'output' in task_data['test'][0]:
                        test_output = task_data['test'][0]['output']
                        logger.info(f"  Test output grid size: {len(test_output)}x{len(test_output[0])}")
            except Exception as e:
                logger.info(f"  Could not decode task structure: {e}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ” Starting manual evaluation check")
    
    # åŠ è½½æ¨¡å‹
    model, device, checkpoint = load_best_model()
    
    # æ‰‹åŠ¨è¯„ä¼°
    manual_evaluation(model, device, num_samples=5)
    
    logger.info(f"\n{'='*60}")
    logger.info("âœ… Manual evaluation completed!")
    logger.info(f"ğŸ“Š Model was saved at step {checkpoint['step']} with:")
    logger.info(f"  - Validation token accuracy: {checkpoint['val_token_acc']:.4f}")
    logger.info(f"  - Validation full accuracy: {checkpoint['val_full_acc']:.4f}")
    logger.info("ğŸ” Check the detailed outputs above for any factual errors")

if __name__ == "__main__":
    main()